---
---

*prnair@ucsd.edu* ‚Ä¢ CV ‚Ä¢ [Google Scholar](https://scholar.google.com/citations?user=8OTteiYAAAAJ&hl=en) ‚Ä¢ [GitHub](https://github.com/pnair7) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/pnair7/)

---

***I'm currently applying for PhD programs in and around computer science for Fall 2024 admission!***

---

**I'm currently advised by [Professor David Danks](https://www.daviddanks.org/) of the Halƒ±cƒ±oƒülu Data Science Institute and Department of Philosophy at UCSD.** My thesis research deals with using active learning in fairness-sensitive decisions that suffer from unobserved counterfactuals, establishing how decisionmakers can benefit epistemically in the long run by observing points that were historically unlikely to be observed.

Prior to my graduate study, I was a data science major at UC San Diego üî±, graduating with minors in history and liguistics, and a concentration in political science. They wouldn't let me triple minor.

Outside the classroom, I was the sports editor of [The UCSD Guardian](https://ucsdguardian.org), I was (and continue to be) in UCSD's quizbowl club, and I spent a summer making a documentary about UCSD's history. In my free time, I'm watching as many sports as I can, reading books at a glacial pace, and reading Wikipedia pages.

---

## üßë‚Äçüíª Research Interests

### If and when we use algorithms to make important social decisions, what will go wrong, and how can we find out?

#### Specifically, that includes:

* **Machine learning fairness:** how can we ensure algorithms make decisions that match our philosophical notions of fairness? What *is* fair, anyway?
  * Can we develop guidelines for algorithmic systems that are fair *from end to end*, from data collection to, ultimately, taking action?
  * How do factors like temporal dynamics,  missingness, or other complications affect how we assess fairness?
  * How can researchers and regulators detect unfairness in the wild?

* **Human-AI interaction**: How do people make sense of and react to algorithmic decisionmaking that affects their lives? How do recent publicly released models affect the relationship between users and ML?

* ...and plenty of other areas where people meet algorithms, such as interpretability, policy, algorithmic auditing, and participatory design.

---

## üìù Publication(s)

**Engagement in online learning: student attitudes and behavior during COVID-19.** Hollister, B., **Nair, P.\***, Hill-Lindsay, S., & Chukoskie, L. Frontiers in Education, May 2022. [https://www.frontiersin.org/articles/10.3389/feduc.2022.851019/full](https://www.frontiersin.org/articles/10.3389/feduc.2022.851019/full)

**\*** ***co-first-author***

---

## ‚úèÔ∏è Teaching

I've been a teaching assistant in the Halƒ±cƒ±oƒülu Data Science Institute for every quarter as a graduate student at UCSD. As a teaching assistant for **DSC 180, the data science senior capstone sequence** (Fall 2022, Winter 2023, [Fall 2023, Winter 2024](https://dsc-capstone.org/)), I've advised and evaluated groups of students as they worked with faculty and industry mentors in a two-quarter project sequence. (The capstone had too few filled evaluations to report numerical results.)

As the lead TA for **DSC 80, Practice and Application of Data Science**, I led live-coding discussions of 80 to 100 students by myself, held *very* busy office hours, and graded assignments. In teaching evaluations, 85.7% of students "strongly agreed" that they would recommend me to other students, while the remainder simply "agreed."

---

*This site was made with [Point Theme](https://github.com/katmh/point-theme), a [Jekyll](https://github.com/katmh) theme by [katmh](https://github.com/katmh). The source for this site is available [here](https://github.com/pnair7/pnair7.github.io). Let me know if I've made any mistakes or if I need to update something!*