---
---

*prnair@ucsd.edu* ‚Ä¢ [CV](/assets/CV.pdf){:target="_blank"} ‚Ä¢ [Google Scholar](https://scholar.google.com/citations?user=8OTteiYAAAAJ&hl=en){:target="_blank"} ‚Ä¢ [GitHub](https://github.com/pnair7){:target="_blank"} ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/pnair7/){:target="_blank"}

At Harvard, supervised by [Professor Amit Goldenberg](https://www.amitgoldenberg.com/){:target="_blank"}, I study the use of artificial intelligence for emotional support and regulation through experimental and machine learning methods. I will help develop large-scale human-AI studies, and support the lab's computational infrastructure.

I recently graduated from UC San Diego üî± with a master's in computer science, where I was advised by [Professor David Danks](https://www.daviddanks.org/){:target="_blank"}. My thesis uses causal inference and active learning to study fairness-sensitive decisions with selective labeling, establishing how even without biased or flawed models, imbalances in group size can lead to differences in uncertainty. 

I was also a teaching assistant in HDSI, supervising the [senior capstone course](https://dsc-capstone.org/){:target="_blank"} and [DSC 80](https://dsc80.com/){:target="_blank"}. Prior to my graduate study, I was a data science major at UC San Diego, graduating with minors in history and liguistics, and a concentration in political science. Outside the classroom, I was the sports editor of [The UCSD Guardian](https://ucsdguardian.org){:target="_blank"}, was in UCSD's quizbowl club, and spent a summer making [a documentary about UCSD's history](https://pnair7.github.io/fun). In my free time, I'm watching as many sports as I can, reading Wikipedia pages, and watching movies.

---

## üßë‚Äçüíª Research Interests

* **Responsible ML:** How do we build decisionmaking systems around algorithms that uphold our values and lead to the outcomes we want? How can researchers and regulators detect unfairness in the wild?

* **Causal inference**: How can we use statistical methods to develop causal notions for discovery? Can the abstractions of causation give us the tools to develop more responsible ML systems?

* **Human-AI Interaction**: How do the ways in which humans perceive and react to algorithmic systems affect the way in which we should design them?

---

*This site was made with [Point Theme](https://github.com/katmh/point-theme), a [Jekyll](https://jekyllrb.com/) theme by [Kat Huang (katmh)](https://github.com/katmh). The source for this site is available [here](https://github.com/pnair7/pnair7.github.io). Let me know if I've made any mistakes or if I need to update something!*
